{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f0479e",
   "metadata": {},
   "source": [
    "# 04. Hybrid Model Training & Evaluation\n",
    "\n",
    "This notebook trains our final hybrid fraud detection model by combining:\n",
    "- Traditional transaction features from our baseline model\n",
    "- Graph network features from our transaction graph\n",
    "\n",
    "Our goal is to beat the baseline ROC-AUC score of **0.9213** using graph-enhanced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3bebd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379f9de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data directory: ..\\app\\artifacts\n",
      "üìÅ Output directory: ..\\app\\artifacts\n",
      "üéØ Baseline ROC-AUC to beat: 0.9213\n"
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "data_dir = Path(\"../app/artifacts\")\n",
    "output_dir = Path(\"../app/artifacts\")\n",
    "\n",
    "print(f\"üìÅ Data directory: {data_dir}\")\n",
    "print(f\"üìÅ Output directory: {output_dir}\")\n",
    "\n",
    "# Define baseline score to beat\n",
    "BASELINE_ROC_AUC = 0.9213\n",
    "print(f\"üéØ Baseline ROC-AUC to beat: {BASELINE_ROC_AUC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cbca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading datasets...\n",
      "‚úÖ Transaction data loaded: (118108, 434)\n",
      "‚úÖ Graph features loaded: (8491, 5)\n",
      "üìä Transaction columns: 434\n",
      "üìä Graph feature columns: ['node', 'degree_centrality', 'pagerank', 'clustering_coefficient', 'betweenness_centrality']\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets\n",
    "print(\"üìä Loading datasets...\")\n",
    "\n",
    "# Load main transaction data\n",
    "transaction_path = data_dir / \"eda_processed_data.csv\"\n",
    "df_transactions = pd.read_csv(transaction_path)\n",
    "\n",
    "# Load graph features\n",
    "graph_path = data_dir / \"graph_features.parquet\"\n",
    "df_graph = pd.read_parquet(graph_path)\n",
    "\n",
    "print(f\"‚úÖ Transaction data loaded: {df_transactions.shape}\")\n",
    "print(f\"‚úÖ Graph features loaded: {df_graph.shape}\")\n",
    "print(f\"üìä Transaction columns: {len(df_transactions.columns)}\")\n",
    "print(f\"üìä Graph feature columns: {df_graph.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e6fb10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Inspecting data for merging...\n",
      "\n",
      "üìä Sample transaction entities:\n",
      "   card1  addr1 P_emaildomain R_emaildomain DeviceType ProductCD\n",
      "0  14223  204.0     gmail.com           NaN        NaN         W\n",
      "1   2516  315.0     yahoo.com           NaN        NaN         W\n",
      "2   7585  272.0     yahoo.com           NaN        NaN         W\n",
      "3  10823    NaN     gmail.com     gmail.com     mobile         C\n",
      "4   9633    NaN   hotmail.com   hotmail.com     mobile         C\n",
      "\n",
      "üìä Sample graph features:\n",
      "                      node  degree_centrality  pagerank  \\\n",
      "0              card1_14223                 11  0.000019   \n",
      "1              addr1_204.0               1055  0.008494   \n",
      "2  P_emaildomain_gmail.com               4990  0.061364   \n",
      "3              ProductCD_W               5850  0.087432   \n",
      "4               card4_visa               4847  0.069541   \n",
      "\n",
      "   clustering_coefficient  betweenness_centrality  \n",
      "0                0.836364            2.468695e-09  \n",
      "1                0.024324            4.835185e-03  \n",
      "2                0.003461            1.301770e-01  \n",
      "3                0.002523            1.868879e-01  \n",
      "4                0.003682            1.397444e-01  \n",
      "\n",
      "üîç Graph node patterns:\n",
      "0\n",
      "card1         8185\n",
      "addr1          174\n",
      "P               59\n",
      "R               58\n",
      "ProductCD        5\n",
      "card4            4\n",
      "card6            4\n",
      "DeviceType       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect data for merging\n",
    "print(\"üîç Inspecting data for merging...\")\n",
    "\n",
    "# Show sample of transaction data key columns\n",
    "key_entity_cols = ['card1', 'addr1', 'P_emaildomain', 'R_emaildomain', 'DeviceType', 'ProductCD']\n",
    "print(\"\\nüìä Sample transaction entities:\")\n",
    "print(df_transactions[key_entity_cols].head())\n",
    "\n",
    "# Show sample of graph features\n",
    "print(\"\\nüìä Sample graph features:\")\n",
    "print(df_graph.head())\n",
    "\n",
    "# Check graph node patterns\n",
    "print(f\"\\nüîç Graph node patterns:\")\n",
    "node_types = df_graph['node'].str.split('_', n=1, expand=True)[0].value_counts()\n",
    "print(node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574b5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Merging graph features with transaction data...\n",
      "üéØ Primary entities for merging: ['card1', 'addr1', 'P_emaildomain']\n",
      "üéØ Secondary entities for merging: ['ProductCD', 'DeviceType', 'card4']\n"
     ]
    }
   ],
   "source": [
    "# Merge Features - Key Step!\n",
    "print(\"üîó Merging graph features with transaction data...\")\n",
    "\n",
    "# Create a copy to work with\n",
    "df_merged = df_transactions.copy()\n",
    "\n",
    "# Define primary and secondary entities for merging\n",
    "primary_entities = ['card1', 'addr1', 'P_emaildomain']  # Most important for fraud\n",
    "secondary_entities = ['ProductCD', 'DeviceType', 'card4']  # Secondary entities\n",
    "\n",
    "print(f\"üéØ Primary entities for merging: {primary_entities}\")\n",
    "print(f\"üéØ Secondary entities for merging: {secondary_entities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41b75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge function\n",
    "def merge_graph_features(df, entity_col, suffix):\n",
    "    \"\"\"Merge graph features for a specific entity column\"\"\"\n",
    "    # Create entity IDs that match graph node format\n",
    "    entity_ids = df[entity_col].astype(str).apply(lambda x: f\"{entity_col}_{x}\" if pd.notna(x) and x != 'nan' else None)\n",
    "    \n",
    "    # Create temporary dataframe for merging\n",
    "    temp_df = pd.DataFrame({\n",
    "        'entity_id': entity_ids,\n",
    "        'index': df.index\n",
    "    }).dropna()\n",
    "    \n",
    "    # Merge with graph features\n",
    "    merged = temp_df.merge(\n",
    "        df_graph.rename(columns={'node': 'entity_id'}), \n",
    "        on='entity_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Rename columns with suffix\n",
    "    feature_cols = ['degree_centrality', 'pagerank', 'clustering_coefficient', 'betweenness_centrality']\n",
    "    for col in feature_cols:\n",
    "        merged[f\"{col}_{suffix}\"] = merged[col]\n",
    "    \n",
    "    # Return only the new features aligned with original dataframe\n",
    "    result = merged.set_index('index')[feature_cols].rename(columns={col: f\"{col}_{suffix}\" for col in feature_cols})\n",
    "    return result.reindex(df.index, fill_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f332b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Starting with 434 columns\n"
     ]
    }
   ],
   "source": [
    "# Start merging\n",
    "original_cols = len(df_merged.columns)\n",
    "print(f\"üìä Starting with {original_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e219287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Merging primary entity features...\n",
      "  Merging card1...\n",
      "    Added 4 features\n",
      "  Merging addr1...\n",
      "    Added 4 features\n",
      "  Merging P_emaildomain...\n",
      "    Added 4 features\n",
      "‚úÖ Primary entities merged. Total columns: 446\n"
     ]
    }
   ],
   "source": [
    "# Merge primary entities (most important)\n",
    "print(\"üîó Merging primary entity features...\")\n",
    "\n",
    "for entity in primary_entities:\n",
    "    if entity in df_merged.columns:\n",
    "        print(f\"  Merging {entity}...\")\n",
    "        graph_features = merge_graph_features(df_merged, entity, entity.lower())\n",
    "        df_merged = pd.concat([df_merged, graph_features], axis=1)\n",
    "        print(f\"    Added {len(graph_features.columns)} features\")\n",
    "\n",
    "print(f\"‚úÖ Primary entities merged. Total columns: {len(df_merged.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024ea62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Merging secondary entity features...\n",
      "  Merging ProductCD...\n",
      "    Added 4 features\n",
      "  Merging DeviceType...\n",
      "    Added 4 features\n",
      "  Merging card4...\n",
      "    Added 4 features\n",
      "‚úÖ Secondary entities merged. Total columns: 458\n"
     ]
    }
   ],
   "source": [
    "# Merge secondary entities\n",
    "print(\"üîó Merging secondary entity features...\")\n",
    "\n",
    "for entity in secondary_entities:\n",
    "    if entity in df_merged.columns:\n",
    "        print(f\"  Merging {entity}...\")\n",
    "        graph_features = merge_graph_features(df_merged, entity, entity.lower())\n",
    "        df_merged = pd.concat([df_merged, graph_features], axis=1)\n",
    "        print(f\"    Added {len(graph_features.columns)} features\")\n",
    "\n",
    "print(f\"‚úÖ Secondary entities merged. Total columns: {len(df_merged.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c23aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Graph feature columns added (24):\n",
      "  - degree_centrality_card1\n",
      "  - pagerank_card1\n",
      "  - clustering_coefficient_card1\n",
      "  - betweenness_centrality_card1\n",
      "  - degree_centrality_addr1\n",
      "  - pagerank_addr1\n",
      "  - clustering_coefficient_addr1\n",
      "  - betweenness_centrality_addr1\n",
      "  - degree_centrality_p_emaildomain\n",
      "  - pagerank_p_emaildomain\n",
      "  - clustering_coefficient_p_emaildomain\n",
      "  - betweenness_centrality_p_emaildomain\n",
      "  - degree_centrality_productcd\n",
      "  - pagerank_productcd\n",
      "  - clustering_coefficient_productcd\n",
      "  - betweenness_centrality_productcd\n",
      "  - degree_centrality_devicetype\n",
      "  - pagerank_devicetype\n",
      "  - clustering_coefficient_devicetype\n",
      "  - betweenness_centrality_devicetype\n",
      "  - degree_centrality_card4\n",
      "  - pagerank_card4\n",
      "  - clustering_coefficient_card4\n",
      "  - betweenness_centrality_card4\n"
     ]
    }
   ],
   "source": [
    "# Show new graph feature columns\n",
    "graph_feature_cols = [col for col in df_merged.columns if any(metric in col for metric in ['degree_centrality', 'pagerank', 'clustering_coefficient', 'betweenness_centrality'])]\n",
    "print(f\"\\nüìä Graph feature columns added ({len(graph_feature_cols)}):\")\n",
    "for col in graph_feature_cols:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a653b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Handling missing values from merging...\n",
      "üìä Missing values in graph features:\n",
      "Series([], dtype: int64)\n",
      "‚úÖ Missing values filled with 0.0\n",
      "üìä Final merged dataset shape: (118108, 458)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values from merging\n",
    "print(\"üîß Handling missing values from merging...\")\n",
    "\n",
    "# Check for missing values in graph features\n",
    "missing_summary = df_merged[graph_feature_cols].isnull().sum()\n",
    "print(f\"üìä Missing values in graph features:\")\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "# Fill missing graph features with 0 (entities not in graph)\n",
    "df_merged[graph_feature_cols] = df_merged[graph_feature_cols].fillna(0.0)\n",
    "\n",
    "print(f\"‚úÖ Missing values filled with 0.0\")\n",
    "print(f\"üìä Final merged dataset shape: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f06aef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Hybrid Feature Summary:\n",
      "==================================================\n",
      "Original transaction features: 434\n",
      "Graph features added: 24\n",
      "Total features: 458\n",
      "\n",
      "üìã Sample of graph features:\n",
      "       degree_centrality_card1  pagerank_card1  clustering_coefficient_card1  \\\n",
      "count            118108.000000   118108.000000                 118108.000000   \n",
      "mean                 44.487240        0.000044                      0.636099   \n",
      "std                  30.917079        0.000030                      0.181294   \n",
      "min                   2.000000        0.000018                      0.000000   \n",
      "25%                  17.000000        0.000020                      0.481422   \n",
      "50%                  40.000000        0.000030                      0.628056   \n",
      "75%                  64.000000        0.000063                      0.763636   \n",
      "max                 121.000000        0.000126                      1.000000   \n",
      "\n",
      "       betweenness_centrality_card1  degree_centrality_addr1  pagerank_addr1  \\\n",
      "count                  1.181080e+05            118108.000000   118108.000000   \n",
      "mean                   1.206988e-06               597.772293        0.004948   \n",
      "std                    2.658049e-06               360.940691        0.003379   \n",
      "min                    0.000000e+00                 0.000000        0.000000   \n",
      "25%                    4.672738e-09               335.000000        0.002296   \n",
      "50%                    1.280735e-07               595.000000        0.004442   \n",
      "75%                    1.416979e-06               922.000000        0.007725   \n",
      "max                    2.150449e-05              1147.000000        0.010892   \n",
      "\n",
      "       clustering_coefficient_addr1  betweenness_centrality_addr1  \\\n",
      "count                 118108.000000                 118108.000000   \n",
      "mean                       0.049604                      0.002265   \n",
      "std                        0.061524                      0.001908   \n",
      "min                        0.000000                      0.000000   \n",
      "25%                        0.020700                      0.000658   \n",
      "50%                        0.038414                      0.001658   \n",
      "75%                        0.062377                      0.003509   \n",
      "max                        1.000000                      0.005716   \n",
      "\n",
      "       degree_centrality_p_emaildomain  pagerank_p_emaildomain  ...  \\\n",
      "count                    118108.000000           118108.000000  ...   \n",
      "mean                       2834.422004                0.032865  ...   \n",
      "std                        1976.838596                0.025172  ...   \n",
      "min                           0.000000                0.000000  ...   \n",
      "25%                         637.000000                0.004211  ...   \n",
      "50%                        3124.000000                0.034685  ...   \n",
      "75%                        4990.000000                0.061364  ...   \n",
      "max                        4990.000000                0.061364  ...   \n",
      "\n",
      "       clustering_coefficient_productcd  betweenness_centrality_productcd  \\\n",
      "count                     118108.000000                     118108.000000   \n",
      "mean                           0.006180                          0.141989   \n",
      "std                            0.007561                          0.076436   \n",
      "min                            0.002523                          0.002127   \n",
      "25%                            0.002523                          0.020137   \n",
      "50%                            0.002523                          0.186888   \n",
      "75%                            0.013353                          0.186888   \n",
      "max                            0.045778                          0.186888   \n",
      "\n",
      "       degree_centrality_devicetype  pagerank_devicetype  \\\n",
      "count                 118108.000000        118108.000000   \n",
      "mean                     705.407796             0.006653   \n",
      "std                     1281.087238             0.012223   \n",
      "min                        0.000000             0.000000   \n",
      "25%                        0.000000             0.000000   \n",
      "50%                        0.000000             0.000000   \n",
      "75%                        0.000000             0.000000   \n",
      "max                     3352.000000             0.032681   \n",
      "\n",
      "       clustering_coefficient_devicetype  betweenness_centrality_devicetype  \\\n",
      "count                      118108.000000                      118108.000000   \n",
      "mean                            0.002274                           0.009791   \n",
      "std                             0.004236                           0.018817   \n",
      "min                             0.000000                           0.000000   \n",
      "25%                             0.000000                           0.000000   \n",
      "50%                             0.000000                           0.000000   \n",
      "75%                             0.000000                           0.000000   \n",
      "max                             0.012604                           0.052533   \n",
      "\n",
      "       degree_centrality_card4  pagerank_card4  clustering_coefficient_card4  \\\n",
      "count            118108.000000   118108.000000                 118108.000000   \n",
      "mean               4160.992151        0.059356                      0.008523   \n",
      "std                1027.746326        0.015262                      0.037522   \n",
      "min                   0.000000        0.000000                      0.000000   \n",
      "25%                3081.000000        0.043342                      0.003682   \n",
      "50%                4847.000000        0.069541                      0.003682   \n",
      "75%                4847.000000        0.069541                      0.005665   \n",
      "max                4847.000000        0.069541                      0.365795   \n",
      "\n",
      "       betweenness_centrality_card4  \n",
      "count                 118108.000000  \n",
      "mean                       0.109833  \n",
      "std                        0.041861  \n",
      "min                        0.000000  \n",
      "25%                        0.058106  \n",
      "50%                        0.139744  \n",
      "75%                        0.139744  \n",
      "max                        0.139744  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Feature summary\n",
    "print(\"üìä Hybrid Feature Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Original transaction features: {original_cols}\")\n",
    "print(f\"Graph features added: {len(graph_feature_cols)}\")\n",
    "print(f\"Total features: {len(df_merged.columns)}\")\n",
    "\n",
    "# Show sample of graph features\n",
    "print(f\"\\nüìã Sample of graph features:\")\n",
    "print(df_merged[graph_feature_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6d1fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Starting feature preprocessing (same as baseline)...\n",
      "‚úÖ Features (X): (118108, 457)\n",
      "‚úÖ Target (y): (118108,)\n",
      "‚úÖ Target distribution: {0: 113975, 1: 4133}\n",
      "üìä Categorical columns: 31\n",
      "üìä Numerical columns: 426\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing (same as baseline)\n",
    "print(\"üîß Starting feature preprocessing (same as baseline)...\")\n",
    "\n",
    "# Separate features and target\n",
    "target_col = 'isFraud'\n",
    "X = df_merged.drop(columns=[target_col])\n",
    "y = df_merged[target_col]\n",
    "\n",
    "print(f\"‚úÖ Features (X): {X.shape}\")\n",
    "print(f\"‚úÖ Target (y): {y.shape}\")\n",
    "print(f\"‚úÖ Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"üìä Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"üìä Numerical columns: {len(numerical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24297f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Handling missing values...\n",
      "üîß Applying frequency encoding...\n",
      "‚úÖ Preprocessing completed\n",
      "üìä Final feature matrix: (118108, 457)\n",
      "üìä Memory usage: 411.80 MB\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in numerical columns\n",
    "print(\"üîß Handling missing values...\")\n",
    "X_numerical = X[numerical_cols].copy()\n",
    "X_numerical = X_numerical.fillna(-999)\n",
    "\n",
    "# Frequency encoding for categorical columns\n",
    "print(\"üîß Applying frequency encoding...\")\n",
    "X_categorical = X[categorical_cols].copy()\n",
    "X_categorical = X_categorical.fillna('MISSING')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    value_counts = X_categorical[col].value_counts()\n",
    "    X_categorical[col] = X_categorical[col].map(value_counts)\n",
    "    X_categorical[col] = X_categorical[col].fillna(0)\n",
    "\n",
    "# Combine features\n",
    "X_processed = pd.concat([X_numerical, X_categorical], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing completed\")\n",
    "print(f\"üìä Final feature matrix: {X_processed.shape}\")\n",
    "print(f\"üìä Memory usage: {X_processed.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bec0f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Splitting data (same as baseline)...\n",
      "‚úÖ Training set: 94486 samples (80.0%)\n",
      "‚úÖ Validation set: 23622 samples (20.0%)\n",
      "‚úÖ Training fraud rate: 0.0350\n",
      "‚úÖ Validation fraud rate: 0.0350\n"
     ]
    }
   ],
   "source": [
    "# Data Split (same as baseline)\n",
    "print(\"‚úÇÔ∏è Splitting data (same as baseline)...\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_processed)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(X_processed)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Training fraud rate: {y_train.mean():.4f}\")\n",
    "print(f\"‚úÖ Validation fraud rate: {y_val.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f42083a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training Hybrid XGBoost model...\n",
      "‚úÖ Hybrid model initialized\n",
      "üìä Training on 457 features (including 24 graph features)\n"
     ]
    }
   ],
   "source": [
    "# Train Hybrid Model (same parameters as baseline)\n",
    "print(\"üöÄ Training Hybrid XGBoost model...\")\n",
    "\n",
    "# Initialize with same parameters as baseline\n",
    "hybrid_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Hybrid model initialized\")\n",
    "print(f\"üìä Training on {X_train.shape[1]} features (including {len(graph_feature_cols)} graph features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e1a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Starting hybrid model training...\n",
      "[0]\tvalidation_0-auc:0.79623\n",
      "[1]\tvalidation_0-auc:0.84421\n",
      "[2]\tvalidation_0-auc:0.85833\n",
      "[3]\tvalidation_0-auc:0.86202\n",
      "[4]\tvalidation_0-auc:0.86333\n",
      "[5]\tvalidation_0-auc:0.86961\n",
      "[6]\tvalidation_0-auc:0.87016\n",
      "[7]\tvalidation_0-auc:0.87275\n",
      "[8]\tvalidation_0-auc:0.87617\n",
      "[9]\tvalidation_0-auc:0.87790\n",
      "[10]\tvalidation_0-auc:0.87881\n",
      "[11]\tvalidation_0-auc:0.88120\n",
      "[12]\tvalidation_0-auc:0.88200\n",
      "[13]\tvalidation_0-auc:0.88364\n",
      "[14]\tvalidation_0-auc:0.88476\n",
      "[15]\tvalidation_0-auc:0.88517\n",
      "[16]\tvalidation_0-auc:0.88650\n",
      "[17]\tvalidation_0-auc:0.88656\n",
      "[18]\tvalidation_0-auc:0.88726\n",
      "[19]\tvalidation_0-auc:0.88864\n",
      "[20]\tvalidation_0-auc:0.88898\n",
      "[21]\tvalidation_0-auc:0.88950\n",
      "[22]\tvalidation_0-auc:0.89021\n",
      "[23]\tvalidation_0-auc:0.89101\n",
      "[24]\tvalidation_0-auc:0.89155\n",
      "[25]\tvalidation_0-auc:0.89193\n",
      "[26]\tvalidation_0-auc:0.89256\n",
      "[27]\tvalidation_0-auc:0.89313\n",
      "[28]\tvalidation_0-auc:0.89356\n",
      "[29]\tvalidation_0-auc:0.89464\n",
      "[30]\tvalidation_0-auc:0.89533\n",
      "[31]\tvalidation_0-auc:0.89524\n",
      "[32]\tvalidation_0-auc:0.89579\n",
      "[33]\tvalidation_0-auc:0.89597\n",
      "[34]\tvalidation_0-auc:0.89666\n",
      "[35]\tvalidation_0-auc:0.89741\n",
      "[36]\tvalidation_0-auc:0.89783\n",
      "[37]\tvalidation_0-auc:0.89822\n",
      "[38]\tvalidation_0-auc:0.89893\n",
      "[39]\tvalidation_0-auc:0.89900\n",
      "[40]\tvalidation_0-auc:0.89930\n",
      "[41]\tvalidation_0-auc:0.89997\n",
      "[42]\tvalidation_0-auc:0.90062\n",
      "[43]\tvalidation_0-auc:0.90107\n",
      "[44]\tvalidation_0-auc:0.90195\n",
      "[45]\tvalidation_0-auc:0.90204\n",
      "[46]\tvalidation_0-auc:0.90252\n",
      "[47]\tvalidation_0-auc:0.90345\n",
      "[48]\tvalidation_0-auc:0.90370\n",
      "[49]\tvalidation_0-auc:0.90403\n",
      "[50]\tvalidation_0-auc:0.90450\n",
      "[51]\tvalidation_0-auc:0.90486\n",
      "[52]\tvalidation_0-auc:0.90556\n",
      "[53]\tvalidation_0-auc:0.90616\n",
      "[54]\tvalidation_0-auc:0.90658\n",
      "[55]\tvalidation_0-auc:0.90683\n",
      "[56]\tvalidation_0-auc:0.90703\n",
      "[57]\tvalidation_0-auc:0.90741\n",
      "[58]\tvalidation_0-auc:0.90749\n",
      "[59]\tvalidation_0-auc:0.90778\n",
      "[60]\tvalidation_0-auc:0.90817\n",
      "[61]\tvalidation_0-auc:0.90851\n",
      "[62]\tvalidation_0-auc:0.90855\n",
      "[63]\tvalidation_0-auc:0.90901\n",
      "[64]\tvalidation_0-auc:0.90906\n",
      "[65]\tvalidation_0-auc:0.90912\n",
      "[66]\tvalidation_0-auc:0.90922\n",
      "[67]\tvalidation_0-auc:0.90928\n",
      "[68]\tvalidation_0-auc:0.90964\n",
      "[69]\tvalidation_0-auc:0.90971\n",
      "[70]\tvalidation_0-auc:0.91014\n",
      "[71]\tvalidation_0-auc:0.91029\n",
      "[72]\tvalidation_0-auc:0.91057\n",
      "[73]\tvalidation_0-auc:0.91088\n",
      "[74]\tvalidation_0-auc:0.91148\n",
      "[75]\tvalidation_0-auc:0.91182\n",
      "[76]\tvalidation_0-auc:0.91226\n",
      "[77]\tvalidation_0-auc:0.91237\n",
      "[78]\tvalidation_0-auc:0.91270\n",
      "[79]\tvalidation_0-auc:0.91287\n",
      "[80]\tvalidation_0-auc:0.91298\n",
      "[81]\tvalidation_0-auc:0.91317\n",
      "[82]\tvalidation_0-auc:0.91348\n",
      "[83]\tvalidation_0-auc:0.91343\n",
      "[84]\tvalidation_0-auc:0.91343\n",
      "[85]\tvalidation_0-auc:0.91354\n",
      "[86]\tvalidation_0-auc:0.91372\n",
      "[87]\tvalidation_0-auc:0.91383\n",
      "[88]\tvalidation_0-auc:0.91444\n",
      "[89]\tvalidation_0-auc:0.91488\n",
      "[90]\tvalidation_0-auc:0.91504\n",
      "[91]\tvalidation_0-auc:0.91499\n",
      "[92]\tvalidation_0-auc:0.91534\n",
      "[93]\tvalidation_0-auc:0.91555\n",
      "[94]\tvalidation_0-auc:0.91562\n",
      "[95]\tvalidation_0-auc:0.91587\n",
      "[96]\tvalidation_0-auc:0.91611\n",
      "[97]\tvalidation_0-auc:0.91626\n",
      "[98]\tvalidation_0-auc:0.91632\n",
      "[99]\tvalidation_0-auc:0.91678\n",
      "[100]\tvalidation_0-auc:0.91728\n",
      "[101]\tvalidation_0-auc:0.91746\n",
      "[102]\tvalidation_0-auc:0.91761\n",
      "[103]\tvalidation_0-auc:0.91782\n",
      "[104]\tvalidation_0-auc:0.91794\n",
      "[105]\tvalidation_0-auc:0.91801\n",
      "[106]\tvalidation_0-auc:0.91800\n",
      "[107]\tvalidation_0-auc:0.91827\n",
      "[108]\tvalidation_0-auc:0.91829\n",
      "[109]\tvalidation_0-auc:0.91836\n",
      "[110]\tvalidation_0-auc:0.91852\n",
      "[111]\tvalidation_0-auc:0.91865\n",
      "[112]\tvalidation_0-auc:0.91883\n",
      "[113]\tvalidation_0-auc:0.91899\n",
      "[114]\tvalidation_0-auc:0.91930\n",
      "[115]\tvalidation_0-auc:0.91930\n",
      "[116]\tvalidation_0-auc:0.91934\n",
      "[117]\tvalidation_0-auc:0.91949\n",
      "[118]\tvalidation_0-auc:0.91951\n",
      "[119]\tvalidation_0-auc:0.91983\n",
      "[120]\tvalidation_0-auc:0.91991\n",
      "[121]\tvalidation_0-auc:0.91993\n",
      "[122]\tvalidation_0-auc:0.91995\n",
      "[123]\tvalidation_0-auc:0.92031\n",
      "[124]\tvalidation_0-auc:0.92020\n",
      "[125]\tvalidation_0-auc:0.92023\n",
      "[126]\tvalidation_0-auc:0.92074\n",
      "[127]\tvalidation_0-auc:0.92063\n",
      "[128]\tvalidation_0-auc:0.92073\n",
      "[129]\tvalidation_0-auc:0.92089\n",
      "[130]\tvalidation_0-auc:0.92130\n",
      "[131]\tvalidation_0-auc:0.92133\n",
      "[132]\tvalidation_0-auc:0.92130\n",
      "[133]\tvalidation_0-auc:0.92133\n",
      "[134]\tvalidation_0-auc:0.92145\n",
      "[135]\tvalidation_0-auc:0.92178\n",
      "[136]\tvalidation_0-auc:0.92193\n",
      "[137]\tvalidation_0-auc:0.92254\n",
      "[138]\tvalidation_0-auc:0.92253\n",
      "[139]\tvalidation_0-auc:0.92270\n",
      "[140]\tvalidation_0-auc:0.92306\n",
      "[141]\tvalidation_0-auc:0.92306\n",
      "[142]\tvalidation_0-auc:0.92326\n",
      "[143]\tvalidation_0-auc:0.92344\n",
      "[144]\tvalidation_0-auc:0.92340\n",
      "[145]\tvalidation_0-auc:0.92339\n",
      "[146]\tvalidation_0-auc:0.92339\n",
      "[147]\tvalidation_0-auc:0.92346\n",
      "[148]\tvalidation_0-auc:0.92350\n",
      "[149]\tvalidation_0-auc:0.92375\n",
      "[150]\tvalidation_0-auc:0.92387\n",
      "[151]\tvalidation_0-auc:0.92386\n",
      "[152]\tvalidation_0-auc:0.92396\n",
      "[153]\tvalidation_0-auc:0.92404\n",
      "[154]\tvalidation_0-auc:0.92408\n",
      "[155]\tvalidation_0-auc:0.92416\n",
      "[156]\tvalidation_0-auc:0.92447\n",
      "[157]\tvalidation_0-auc:0.92471\n",
      "[158]\tvalidation_0-auc:0.92483\n",
      "[159]\tvalidation_0-auc:0.92477\n",
      "[160]\tvalidation_0-auc:0.92469\n",
      "[161]\tvalidation_0-auc:0.92497\n",
      "[162]\tvalidation_0-auc:0.92502\n",
      "[163]\tvalidation_0-auc:0.92498\n",
      "[164]\tvalidation_0-auc:0.92495\n",
      "[165]\tvalidation_0-auc:0.92505\n",
      "[166]\tvalidation_0-auc:0.92550\n",
      "[167]\tvalidation_0-auc:0.92545\n",
      "[168]\tvalidation_0-auc:0.92567\n",
      "[169]\tvalidation_0-auc:0.92575\n",
      "[170]\tvalidation_0-auc:0.92590\n",
      "[171]\tvalidation_0-auc:0.92592\n",
      "[172]\tvalidation_0-auc:0.92592\n",
      "[173]\tvalidation_0-auc:0.92628\n",
      "[174]\tvalidation_0-auc:0.92627\n",
      "[175]\tvalidation_0-auc:0.92626\n",
      "[176]\tvalidation_0-auc:0.92614\n",
      "[177]\tvalidation_0-auc:0.92632\n",
      "[178]\tvalidation_0-auc:0.92623\n",
      "[179]\tvalidation_0-auc:0.92613\n",
      "[180]\tvalidation_0-auc:0.92613\n",
      "[181]\tvalidation_0-auc:0.92618\n",
      "[182]\tvalidation_0-auc:0.92617\n",
      "[183]\tvalidation_0-auc:0.92629\n",
      "[184]\tvalidation_0-auc:0.92615\n",
      "[185]\tvalidation_0-auc:0.92616\n",
      "[186]\tvalidation_0-auc:0.92619\n",
      "‚úÖ Hybrid model training completed!\n",
      "üìä Best iteration: 177\n",
      "üìä Best validation AUC: 0.9263\n"
     ]
    }
   ],
   "source": [
    "# Train the hybrid model\n",
    "print(\"üî• Starting hybrid model training...\")\n",
    "\n",
    "hybrid_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Hybrid model training completed!\")\n",
    "print(f\"üìä Best iteration: {hybrid_model.best_iteration}\")\n",
    "print(f\"üìä Best validation AUC: {hybrid_model.best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "512d6b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating hybrid model performance...\n",
      "üéØ PERFORMANCE COMPARISON:\n",
      "============================================================\n",
      "Baseline ROC-AUC:     0.9213\n",
      "Hybrid ROC-AUC:       0.9263\n",
      "Improvement:          +0.0050\n",
      "Relative Improvement: +0.54%\n",
      "============================================================\n",
      "üéâ SUCCESS! Graph features improved the model!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and Compare Performance\n",
    "print(\"üìä Evaluating hybrid model performance...\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = hybrid_model.predict_proba(X_val)[:, 1]\n",
    "y_pred = hybrid_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "hybrid_roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(\"üéØ PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Baseline ROC-AUC:     {BASELINE_ROC_AUC:.4f}\")\n",
    "print(f\"Hybrid ROC-AUC:       {hybrid_roc_auc:.4f}\")\n",
    "print(f\"Improvement:          {hybrid_roc_auc - BASELINE_ROC_AUC:+.4f}\")\n",
    "print(f\"Relative Improvement: {((hybrid_roc_auc - BASELINE_ROC_AUC) / BASELINE_ROC_AUC * 100):+.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hybrid_roc_auc > BASELINE_ROC_AUC:\n",
    "    print(\"üéâ SUCCESS! Graph features improved the model!\")\n",
    "else:\n",
    "    print(\"ü§î Graph features didn't improve performance. Need investigation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "598cc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Detailed Performance Metrics:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.98      1.00      0.99     22795\n",
      "       Fraud       0.90      0.42      0.57       827\n",
      "\n",
      "    accuracy                           0.98     23622\n",
      "   macro avg       0.94      0.71      0.78     23622\n",
      "weighted avg       0.98      0.98      0.97     23622\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Detailed performance metrics\n",
    "print(\"üìã Detailed Performance Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_val, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca5a08c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing feature importance...\n",
      "üèÜ Top 20 Most Important Features:\n",
      "                         feature  importance\n",
      "297                         V258    0.210359\n",
      "240                         V201    0.051369\n",
      "228                         V189    0.050857\n",
      "18                            C8    0.026764\n",
      "109                          V70    0.019346\n",
      "108                          V69    0.017547\n",
      "129                          V90    0.016753\n",
      "323                         V284    0.015767\n",
      "130                          V91    0.014120\n",
      "24                           C14    0.012966\n",
      "284                         V245    0.010939\n",
      "347                         V308    0.010584\n",
      "333                         V294    0.007579\n",
      "22                           C12    0.007442\n",
      "245                         V206    0.006742\n",
      "211                         V172    0.006633\n",
      "87                           V48    0.006393\n",
      "414  degree_centrality_productcd    0.006177\n",
      "177                         V138    0.006157\n",
      "14                            C4    0.006142\n",
      "\n",
      "üìä Graph features in top 20: 1/20\n",
      "  #18: degree_centrality_productcd (importance: 0.0062)\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "print(\"üîç Analyzing feature importance...\")\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_processed.columns,\n",
    "    'importance': hybrid_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"üèÜ Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Check how many graph features are in top 20\n",
    "top_20_features = feature_importance.head(20)['feature'].tolist()\n",
    "graph_features_in_top20 = [f for f in top_20_features if any(metric in f for metric in ['degree_centrality', 'pagerank', 'clustering_coefficient', 'betweenness_centrality'])]\n",
    "\n",
    "print(f\"\\nüìä Graph features in top 20: {len(graph_features_in_top20)}/20\")\n",
    "for gf in graph_features_in_top20:\n",
    "    rank = top_20_features.index(gf) + 1\n",
    "    importance = feature_importance[feature_importance['feature'] == gf]['importance'].iloc[0]\n",
    "    print(f\"  #{rank}: {gf} (importance: {importance:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9609068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating feature importance visualization...\n",
      "‚úÖ Feature importance plot saved as 'hybrid_feature_importance.png'\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance Visualization\n",
    "print(\"üìä Creating feature importance visualization...\")\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_features = feature_importance.head(20)\n",
    "\n",
    "# Color graph features differently\n",
    "colors = ['red' if any(metric in feat for metric in ['degree_centrality', 'pagerank', 'clustering_coefficient', 'betweenness_centrality']) else 'steelblue' for feat in top_features['feature']]\n",
    "\n",
    "bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Most Important Features (Hybrid Model)\\nRed = Graph Features, Blue = Traditional Features')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add importance values on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hybrid_feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"‚úÖ Feature importance plot saved as 'hybrid_feature_importance.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fe28f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving hybrid model...\n",
      "‚úÖ Hybrid model saved to: ..\\app\\artifacts\\hybrid_model.pkl\n",
      "‚úÖ Hybrid feature names saved to: ..\\app\\artifacts\\hybrid_feature_names.pkl\n",
      "‚úÖ Hybrid feature importance saved to: ..\\app\\artifacts\\hybrid_feature_importance.csv\n",
      "\n",
      "üéâ HYBRID MODEL TRAINING COMPLETED!\n",
      "üèÜ Final ROC-AUC Score: 0.9263\n",
      "üìà Improvement over baseline: +0.0050\n"
     ]
    }
   ],
   "source": [
    "# Save Final Model\n",
    "print(\"üíæ Saving hybrid model...\")\n",
    "\n",
    "# Save the trained hybrid model\n",
    "model_path = output_dir / \"hybrid_model.pkl\"\n",
    "joblib.dump(hybrid_model, model_path)\n",
    "print(f\"‚úÖ Hybrid model saved to: {model_path}\")\n",
    "\n",
    "# Save hybrid feature names\n",
    "feature_names_path = output_dir / \"hybrid_feature_names.pkl\"\n",
    "joblib.dump(X_processed.columns.tolist(), feature_names_path)\n",
    "print(f\"‚úÖ Hybrid feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Save hybrid feature importance\n",
    "importance_path = output_dir / \"hybrid_feature_importance.csv\"\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "print(f\"‚úÖ Hybrid feature importance saved to: {importance_path}\")\n",
    "\n",
    "print(\"\\nüéâ HYBRID MODEL TRAINING COMPLETED!\")\n",
    "print(f\"üèÜ Final ROC-AUC Score: {hybrid_roc_auc:.4f}\")\n",
    "print(f\"üìà Improvement over baseline: {hybrid_roc_auc - BASELINE_ROC_AUC:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3dd41f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã FINAL HYBRID MODEL SUMMARY:\n",
      "==================================================\n",
      "üìä Dataset size: 118,108 transactions\n",
      "üìä Total features: 457\n",
      "üìä Graph features: 24\n",
      "üìä Traditional features: 433\n",
      "üìä Fraud rate: 0.0350\n",
      "\n",
      "üéØ PERFORMANCE:\n",
      "Baseline ROC-AUC:  0.9213\n",
      "Hybrid ROC-AUC:    0.9263\n",
      "Improvement:       +0.0050\n",
      "Success:           ‚úÖ YES\n",
      "\n",
      "üèÜ Graph features impact:\n",
      "Graph features in top 20: 1/20\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Summary\n",
    "print(\"üìã FINAL HYBRID MODEL SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Dataset size: {len(df_merged):,} transactions\")\n",
    "print(f\"üìä Total features: {X_processed.shape[1]:,}\")\n",
    "print(f\"üìä Graph features: {len(graph_feature_cols)}\")\n",
    "print(f\"üìä Traditional features: {X_processed.shape[1] - len(graph_feature_cols)}\")\n",
    "print(f\"üìä Fraud rate: {y.mean():.4f}\")\n",
    "print(\"\\nüéØ PERFORMANCE:\")\n",
    "print(f\"Baseline ROC-AUC:  {BASELINE_ROC_AUC:.4f}\")\n",
    "print(f\"Hybrid ROC-AUC:    {hybrid_roc_auc:.4f}\")\n",
    "print(f\"Improvement:       {hybrid_roc_auc - BASELINE_ROC_AUC:+.4f}\")\n",
    "print(f\"Success:           {'‚úÖ YES' if hybrid_roc_auc > BASELINE_ROC_AUC else '‚ùå NO'}\")\n",
    "print(\"\\nüèÜ Graph features impact:\")\n",
    "print(f\"Graph features in top 20: {len(graph_features_in_top20)}/20\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
